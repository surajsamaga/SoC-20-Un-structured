{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg02JLxV50wu",
        "colab_type": "code",
        "outputId": "e77af1c7-e0a9-4783-943c-29e267e269a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "!pip install trdg\n",
        "from trdg.generators import GeneratorFromStrings  # used for generating text images for training \n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import os\n",
        "import copy\n",
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting trdg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/de/c9783021266b0bf81386eb83590e0280c6fe15ca8a49d700bc2d9675d4c4/trdg-1.6.0-py3-none-any.whl (49.9MB)\n",
            "\u001b[K     |████████████████████████████████| 49.9MB 62kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from trdg) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from trdg) (4.6.3)\n",
            "Collecting opencv-python>=4.2.0.32\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c2/e9cf54ae5b1102020ef895866a67cb2e1aef72f16dd1fde5b5fb1495ad9c/opencv_python-4.2.0.34-cp36-cp36m-manylinux1_x86_64.whl (28.2MB)\n",
            "\u001b[K     |████████████████████████████████| 28.2MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from trdg) (7.0.0)\n",
            "Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from trdg) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.6/dist-packages (from trdg) (1.18.4)\n",
            "Collecting diffimg==0.2.3\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/fa/de925a7c2203b52f007ad6b9cce343c21dbe389a221a4f51f25960c83d8b/diffimg-0.2.3.tar.gz\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trdg) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trdg) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trdg) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trdg) (1.24.3)\n",
            "Building wheels for collected packages: diffimg\n",
            "  Building wheel for diffimg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffimg: filename=diffimg-0.2.3-cp36-none-any.whl size=4049 sha256=8bb5cf3b8358c5eae7c1a68088a15dfdda3688327a634ac70f47f088ece5a6d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/46/95/1de38a4ccb7811e6cc67fcc3594ea25180f85b70c406bdf0c3\n",
            "Successfully built diffimg\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python, diffimg, trdg\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed diffimg-0.2.3 opencv-python-4.2.0.34 trdg-1.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxJdK3k859lk",
        "colab_type": "code",
        "outputId": "ebf126f9-f4b0-4909-b89f-7b20baa2c37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import SGD\n",
        "from keras.losses import categorical_crossentropy \n",
        "from keras.utils import Sequence\n",
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Epz9yOZx5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f0gpuQb6AWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load lists with image information\n",
        "with open('/content/drive/My Drive/SVT/train_images_.pickle', 'rb') as fp:\n",
        "  train_images = pickle.load(fp)\n",
        "with open('/content/drive/My Drive/SVT/val_images_.pickle', 'rb') as fp:\n",
        "  valid_images = pickle.load(fp)\n",
        "with open('/content/drive/My Drive/SVT/test_images_.pickle', 'rb') as fp:\n",
        "  test_images = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaTqSenH6CQO",
        "colab_type": "code",
        "outputId": "83f6ec17-0dcd-4000-8ef8-0f9480deb763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('/content/drive/My Drive/SVT/FINAL_LEXICON.pickle', 'rb') as fp:\n",
        "  # load list of possible output words\n",
        "  LEXICON = pickle.load(fp)\n",
        "print(LEXICON[:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BLOOD', 'MICHAEL', 'FRANCIS', 'DELI', 'SHOCKS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mkb7vFy6Jb9",
        "colab_type": "code",
        "outputId": "f4355821-6442-4939-970d-c6729bf8a4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# prepare final list of words to be fed into GeneratorFromStrings to generate images  \n",
        "caps = LEXICON *4\n",
        "titles = [ele.title() for ele in caps]\n",
        "list_concat = []\n",
        "list_concat.append(caps)\n",
        "list_concat.append(titles)\n",
        "NEW_LEX = [item for sublist in list_concat for item in sublist]\n",
        "print(len(NEW_LEX)) # GLOBAL\n",
        "print(NEW_LEX[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42904\n",
            "['BLOOD', 'MICHAEL', 'FRANCIS', 'DELI', 'SHOCKS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4tos4COIbBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## DOWNLOAD AND USE GOOGLE FONTS TO IMPROVE RESULTS, not used due to memory issues ########\n",
        "\n",
        "# download google fonts from https://github.com/google/fonts/archive/master.zip\n",
        "\n",
        "# def getfonts(dirname):\n",
        "#   # dirname - directory where the fonts directories are stored\n",
        "#   path = os.path.join('/content/drive/My Drive/SVT',dirname)\n",
        "#   fontnames = []\n",
        "#   for font in os.listdir(path):\n",
        "#     fontnames.append(font)\n",
        "#   return fontnames\n",
        "\n",
        "# FONTNAMES = getfonts('ofl')  #GLOBAL\n",
        "# random.shuffle(FONTNAMES)\n",
        "# FINALFONTS = FONTNAMES[:100]\n",
        "\n",
        "# def get_random_font(dirname):\n",
        "#   # dirname - directory where the fonts directories are stored\n",
        "#   path = os.path.join('/content/drive/My Drive/SVT', dirname)\n",
        "\n",
        "#   inp = random.choice(FINALFONTS)\n",
        "#   result = [each for each in os.listdir(os.path.join(path, inp)) if each.endswith('.ttf')]\n",
        "#   fname = random.choice(result)\n",
        "#   fonts = [os.path.join(os.path.join(path, inp), fname)]\n",
        "#   return fonts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCuGhyVt6LfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainBatchGenerator(Sequence):\n",
        "  # Batch Generator which outputs x_batch(images), y_batch(labels)\n",
        "\n",
        "  def __init__(self, image_wordlist, label_wordlist, config, shuffle = True):\n",
        "    \n",
        "    self.config = config  # dictionary with relevant image information \n",
        "    self.wordlist = image_wordlist.copy()  #  lexicon to be used for image (x) generation\n",
        "    self.ylist = label_wordlist.copy()  # lexicon to be used for label (y) generation\n",
        "    self.num_classes = len(self.ylist) # number of labels (to be incrementally increased)\n",
        "    self.shuffle = shuffle\n",
        "\n",
        "  def __len__(self):\n",
        "    # denotes number of batches per epoch\n",
        "    return int(np.ceil(float(len(self.wordlist)) / self.config['BATCH_SIZE']))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    # shuffle at end of epoch for variability\n",
        "    if self.shuffle:\n",
        "      random.shuffle(self.wordlist)\n",
        "\n",
        "  def preprocess(self, image, invert_colours = False):\n",
        "    # preprocess image-\n",
        "    img = np.asarray(image).astype('float32')\n",
        "    img = cv2.resize(img, (self.config['IMAGE_W'], self.config['IMAGE_H']))\n",
        "    img = cv2.GaussianBlur(img, (5,5), 0)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    maxIntensity = 255.0 \n",
        "    phi = 1\n",
        "    theta = 1\n",
        "\n",
        "    if invert_colours:# if black background, white text\n",
        "      img = 255 - img\n",
        "      img = (maxIntensity/phi)*(img/(maxIntensity/theta))**0.5\n",
        "    else:\n",
        "      img = (maxIntensity/phi)*(img/(maxIntensity/theta))**2\n",
        "\n",
        "    img =img.astype('float32')\n",
        "    mean, std = cv2.meanStdDev(img)\n",
        "    img = (img-mean)/std\n",
        "    img = img.reshape((self.config['IMAGE_H'], self.config['IMAGE_W'], self.config['N_C']))\n",
        "    return img\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # to find the left and right bounds for x_batch and y_batch creation\n",
        "    l_bound = idx * self.config['BATCH_SIZE']\n",
        "    r_bound = (idx + 1) * self.config['BATCH_SIZE']\n",
        "    if r_bound > len(self.wordlist):\n",
        "      r_bound = len(self.wordlist)\n",
        "      l_bound = r_bound - self.config['BATCH_SIZE']\n",
        "\n",
        "    use_list = self.wordlist[l_bound:r_bound].copy()  #slice wordlist to generate img, lbl\n",
        "\n",
        "    x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'], self.config['N_C']))\n",
        "    y_batch = np.zeros((r_bound - l_bound, self.num_classes)) \n",
        "\n",
        "    instance_count = 0\n",
        "\n",
        "    for element in use_list:\n",
        "      # generate images with different distortion, skew and backgrounds\n",
        "      mygenerator = GeneratorFromStrings([element], count = 1, text_color = '#000000', background_type = random.choice([0,1]),\n",
        "                           distorsion_type=random.choice([0,1]), distorsion_orientation= random.choice([0,1]),\n",
        "                           skewing_angle = random.randint(354,366),margins = (2,2,2,2), fit = True)\n",
        "      \n",
        "      for img, lbl in mygenerator:  # iterating over 1 image, label pair only\n",
        "        img = self.preprocess(img, random.choice([True, False]))\n",
        "        x_batch[instance_count] = img \n",
        "\n",
        "        if lbl.upper() in self.ylist: # .upper() as LEXICON (list of labels) has only uppercase words, whereas dataset has both \n",
        "          index = self.ylist.index(lbl.upper())\n",
        "          y_batch[instance_count, index] = 1\n",
        "\n",
        "      instance_count += 1\n",
        "    \n",
        "    p = np.random.permutation(x_batch.shape[0]) # shuffle x and y before output for better results\n",
        "    x_batch = x_batch[p]\n",
        "    y_batch = y_batch[p] \n",
        "    return x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vicSnl5k6PHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVTGen(img_dict, label_wordlist, config_dict):\n",
        "  '''\n",
        "  Generate images and labels from svt datasets\n",
        "  Not using generator as batchsize needs to be fixed, but number of cropped regions from a particular image is variable\n",
        "  inputs-\n",
        "    img_dict - list of dicts with image info\n",
        "    label_wordlist - list of words in lexicon to map the labels\n",
        "    config_dict - dict with info about image size\n",
        "  outputs -\n",
        "    x_train, y_train - images, labels of shape (total_obj_num,32,100,1) and (total_obj_num, 4832)\n",
        "  '''\n",
        "  obj_num = 0\n",
        "  for inst in img_dict: # generating total number of images \n",
        "    obj_num += len(inst['object'])\n",
        "      \n",
        "  x_train = np.zeros((obj_num, config_dict['IMAGE_H'], config_dict['IMAGE_W'], config_dict['N_C']))\n",
        "  y_train = np.zeros((obj_num, len(label_wordlist)))\n",
        "  instance_count = 0\n",
        "\n",
        "  for train_instance in img_dict:\n",
        "    fname = train_instance['filename']\n",
        "    img = cv2.imread(fname)\n",
        "\n",
        "    for obj in train_instance['object']:\n",
        "      c_img = img[obj['ymin']:obj['ymax'], obj['xmin']:obj['xmax']].copy()\n",
        "      # scaling image as predicted boxes may not be perfect\n",
        "      # h,w,c = c_img.shape\n",
        "      # if aug:\n",
        "      #   ### scale the image, by 0 to 10%\n",
        "      #   scale = np.random.uniform()/4. + 1.  \n",
        "      #   c_img = cv2.resize(c_img, (0,0), fx = scale, fy = scale)\n",
        "\n",
        "      #   ### translate the image\n",
        "      #   max_offx = (scale-1.) * w\n",
        "      #   max_offy = (scale-1.) * h\n",
        "      #   offx = int(np.random.uniform() * max_offx)\n",
        "      #   offy = int(np.random.uniform() * max_offy)\n",
        "            \n",
        "      #   c_img = c_img[offy : (offy + h), offx : (offx + w)]\n",
        "\n",
        "      c_img = cv2.resize(c_img, (config_dict['IMAGE_W'], config_dict['IMAGE_H']))\n",
        "      c_img = cv2.GaussianBlur(c_img, (5,5), 0)\n",
        "      c_img = cv2.cvtColor(c_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      # maxIntensity = 255.0 \n",
        "      # phi = 1\n",
        "      # theta = 1\n",
        "\n",
        "      # c_img = (maxIntensity/phi)*(c_img/(maxIntensity/theta))**2\n",
        "      # c_img = c_img.astype('float32')\n",
        "\n",
        "      mean, std = cv2.meanStdDev(c_img)\n",
        "      c_img = (c_img-mean)/std\n",
        "      x_train[instance_count] = c_img.reshape(config_dict['IMAGE_H'], config_dict['IMAGE_W'], config_dict['N_C'])\n",
        "\n",
        "      lbl = obj['label']\n",
        "      if lbl in label_wordlist:\n",
        "        index = label_wordlist.index(lbl)\n",
        "        y_train[instance_count, index] = 1\n",
        "\n",
        "      instance_count += 1\n",
        "  return x_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylxQCTtX6TRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SVT_2(Sequence):\n",
        "  # batch generator for svt data, only reorganizes xtrain, ytrain obtained from SVTGen into tensors of fixed batch size\n",
        "  \n",
        "  def __init__(self, xtrain, ytrain, batch_size, shuffle = True):\n",
        "    self.xtrain = xtrain.copy()\n",
        "    self.ytrain = ytrain.copy()\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = True\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.ceil(float(self.xtrain.shape[0])/self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle:\n",
        "      p = np.random.permutation(self.xtrain.shape[0])\n",
        "      self.xtrain = self.xtrain[p]\n",
        "      self.ytrain = self.ytrain[p]\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    l_bound = idx * self.batch_size\n",
        "    r_bound = (idx + 1) * self.batch_size\n",
        "    if r_bound > (self.xtrain.shape[0]):\n",
        "      r_bound = (self.xtrain.shape[0])\n",
        "      l_bound = r_bound - self.batch_size\n",
        "    x_batch = self.xtrain[l_bound:r_bound].copy()\n",
        "    y_batch = self.ytrain[l_bound:r_bound].copy()\n",
        "\n",
        "    p = np.random.permutation(x_batch.shape[0])\n",
        "    x_batch = x_batch[p]\n",
        "    y_batch = y_batch[p] \n",
        "    return x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKiesp2o6Wz2",
        "colab_type": "code",
        "outputId": "a9236999-9264-4638-f2b8-116e920fa642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_config = {\n",
        "    'BATCH_SIZE'  : 1024, # using large batch size else model doesn't learn well\n",
        "    'IMAGE_H'     : 32,\n",
        "    'IMAGE_W'     : 100,\n",
        "    'N_C'         : 1\n",
        "}\n",
        "svt_config = {\n",
        "    'IMAGE_H'     : 32,\n",
        "    'IMAGE_W'     : 100,\n",
        "    'N_C'         : 1\n",
        "}\n",
        "NUM_CLASSES = len(LEXICON)  # global variable denoting number of classes (words) in the final softmax layer\n",
        "print(NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFPJeyJB6Xqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch = TrainBatchGenerator(NEW_LEX,LEXICON, train_config)\n",
        "xtrain, ytrain = SVTGen(train_images, LEXICON, svt_config)\n",
        "svt_batch = SVT_2(xtrain, ytrain, 64) # batchsize = 64 for svt data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_u18Bs5Mmwv",
        "colab_type": "code",
        "outputId": "e7d68873-8c5e-4d38-898a-968aeb00514a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "j = 23\n",
        "xt, yt = train_batch.__getitem__(0)\n",
        "plt.imshow(xt[j].reshape((32,100)), cmap = 'gray')\n",
        "print(LEXICON[np.argmax(yt[j])])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BRAKES\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amCB1Xevw90R",
        "colab_type": "code",
        "outputId": "663b847b-d433-4c6d-a5c2-9755f2770659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "xv, yv = svt_batch.__getitem__(0)\n",
        "plt.imshow(xv[j].reshape((32,100)), cmap = 'gray')\n",
        "print(LEXICON[np.argmax(yv[j])])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SHOE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjxE7RIM6bss",
        "colab_type": "code",
        "outputId": "3a4f1f39-bc92-456f-82ae-cd8481b99cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def get_model(IM_H, IM_W, N_C, num_classes):\n",
        "  inp = Input(shape = (IM_H, IM_W, N_C))\n",
        "\n",
        "  x = Conv2D(filters = 64, kernel_size = 5, padding = 'same')(inp)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  # x = Dropout(0.2)(x)\n",
        "  x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "  x = Conv2D(filters = 128, kernel_size = 5, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  # x = Dropout(0.2)(x)\n",
        "  x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "  x = Conv2D(filters = 256, kernel_size = 3, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  # x = Dropout(0.2)(x)\n",
        "  x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "  x = Conv2D(filters = 512, kernel_size = 3, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  # x = Dropout(0.2)(x)\n",
        "  # x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "  x = Conv2D(filters = 512, kernel_size = 3, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  # x = Dropout(0.2)(x)\n",
        "  x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  x = Dense(units = 4000)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "\n",
        "  x = Dense(units = 4000)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "\n",
        "  outputs = Dense(units = num_classes, activation = 'softmax')(x)\n",
        "\n",
        "  model = Model(inputs= inp, outputs = outputs)\n",
        "  return model\n",
        "model = get_model(train_config['IMAGE_H'], train_config['IMAGE_W'], train_config['N_C'], NUM_CLASSES)\n",
        "model.summary()\n",
        "# model.load_weights('/content/drive/My Drive/SVT/cnn_model/final_model_150ep.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32, 100, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 100, 64)       1664      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 100, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 100, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 50, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 50, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 50, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 25, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 25, 256)        295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 25, 256)        1024      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 25, 256)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 12, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 12, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 12, 512)        2048      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4, 12, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 12, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4, 12, 512)        2048      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 12, 512)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6144)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4000)              24580000  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4000)              16000     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4000)              16004000  \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4000)              16000     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5363)              21457363  \n",
            "=================================================================\n",
            "Total params: 66,120,979\n",
            "Trainable params: 66,102,035\n",
            "Non-trainable params: 18,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgZg_pDv6iQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = keras.optimizers.sgd(lr = 0.01, decay = 0.01/150), loss = categorical_crossentropy, metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt89tS-c6lyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/SVT/cnn_model/final150ep.h5', \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='min', \n",
        "                             period=1)\n",
        "history = model.fit_generator(generator = train_batch, \n",
        "                    steps_per_epoch  = len(train_batch), \n",
        "                    epochs           = 150, \n",
        "                    verbose          = 1,\n",
        "                    validation_data  = svt_batch,\n",
        "                    validation_steps = len(svt_batch),\n",
        "                    callbacks        = [checkpoint], \n",
        "                    max_queue_size   = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz5b2GxJAnfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint1 = ModelCheckpoint('/content/drive/My Drive/SVT/cnn_model/final300ep.h5', \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='min', \n",
        "                             period=1)\n",
        "history = model.fit_generator(generator = train_batch, \n",
        "                    steps_per_epoch  = len(train_batch), \n",
        "                    epochs           = 150, \n",
        "                    verbose          = 1,\n",
        "                    validation_data  = svt_batch,\n",
        "                    validation_steps = len(svt_batch),\n",
        "                    callbacks        = [checkpoint1], \n",
        "                    max_queue_size   = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO5WISsstVHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now train on svt data \n",
        "newxtrain, newytrain = SVTGen(train_images, LEXICON, svt_config)\n",
        "svttrain = SVT_2(newxtrain, newytrain, 16)\n",
        "newxvalid, newyvalid = SVTGen(valid_images,LEXICON, svt_config)  \n",
        "svtvalid = SVT_2(newxvalid,newyvalid, 16)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yal9FsJ32p7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = get_model(train_config['IMAGE_H'], train_config['IMAGE_W'], train_config['N_C'], NUM_CLASSES)\n",
        "model2.load_weights('/content/drive/My Drive/SVT/cnn_model/final300ep.h5')\n",
        "model2.compile(optimizer = keras.optimizers.sgd(lr = 0.001), loss = categorical_crossentropy, metrics = ['accuracy'])\n",
        "\n",
        "checkpoint3 = ModelCheckpoint('/content/drive/My Drive/SVT/cnn_model/final_svttrain_v3.h5', \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='min', \n",
        "                             period=1) \n",
        "\n",
        "\n",
        "hist1 = model2.fit_generator(generator = svttrain, \n",
        "                    steps_per_epoch  = len(svttrain), \n",
        "                    epochs           = 75, \n",
        "                    verbose          = 1,\n",
        "                    validation_data  = svtvalid,\n",
        "                    validation_steps = len(svtvalid),\n",
        "                    callbacks        = [checkpoint3], \n",
        "                    max_queue_size   = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuLJT_PfYXYf",
        "colab_type": "code",
        "outputId": "c39a59b9-eebc-4e0e-b77a-4e261a7735f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model3 = load_model('/content/drive/My Drive/SVT/cnn_model/final_svttrain.h5')\n",
        "model3.evaluate(newxvalid, newyvalid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "136/136 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.234180843128877, 0.38235294818878174]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    }
  ]
}